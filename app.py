# app.py
import os
from dotenv import load_dotenv
import chromadb
import dashscope
from dashscope import Generation, TextEmbedding
from dashscope import Generation

# ============ åŠ è½½ç¯å¢ƒå˜é‡ ============
load_dotenv()
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
# ====================================================

dashscope.base_http_api_url = 'https://dashscope.aliyuncs.com/api/v1' # ä¸ºAPIè¯·æ±‚æä¾›åœ°å€

# ========== é…ç½®é¡¹ (è¯·ä¸build_vector_db.pyä¿æŒä¸€è‡´) ==========
KNOWLEDGE_BASE_DIR = "knowledge_base"
CHROMA_DB_DIR = "db/chroma_db"
COLLECTION_NAME = "linux_commands"


# ====================================================

def get_embeddings(texts):
    """
    ä½¿ç”¨é˜¿é‡Œäº‘ text-embedding-v3 æ¨¡å‹æ‰¹é‡è·å–æ–‡æœ¬åµŒå…¥å‘é‡ã€‚
    """
    if not isinstance(texts, list):
        texts = [texts]
        
    response = TextEmbedding.call(
        model='text-embedding-v3',
        input=texts,
        api_key=DASHSCOPE_API_KEY
    )
    
    if response.status_code == 200:
        # 'dense' æ˜¯é»˜è®¤çš„å‘é‡ç±»å‹
        embeddings = [item['embedding'] for item in response.output['embeddings']]
        return embeddings
    else:
        raise Exception(f"åµŒå…¥APIè°ƒç”¨å¤±è´¥: {response.code}, {response.message}")

def retrieve_context(query, n_results=3):
    """
    æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ï¼Œä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢æœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡æ–‡æœ¬å—ã€‚
    ä½¿ç”¨é˜¿é‡Œäº‘ text-embedding-v3 è¿›è¡ŒæŸ¥è¯¢ã€‚
    """
    try:
        # 1. ä¸ºæŸ¥è¯¢æ–‡æœ¬ç”ŸæˆåµŒå…¥
        query_embedding = get_embeddings(query)[0] # get_embeddings è¿”å›åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ª
        
        # 2. è¿æ¥åˆ°æ•°æ®åº“å¹¶æŸ¥è¯¢
        client = chromadb.PersistentClient(path=CHROMA_DB_DIR)
        collection = client.get_collection(name=COLLECTION_NAME)
        
        results = collection.query(
            query_embeddings=[query_embedding], # æ³¨æ„è¿™é‡Œæ˜¯ query_embeddings
            n_results=n_results
        )
        return results['documents'][0] if results['documents'] else []
        
    except Exception as e:
        print(f"æ£€ç´¢æ—¶å‡ºé”™: {e}")
        return []


def call_qwen_api(prompt, model='qwen3-max'):
    """
    è°ƒç”¨é€šä¹‰åƒé—®APIç”Ÿæˆå›ç­”ã€‚
    """
    # è®¾ç½®API Key
    Generation.api_key = DASHSCOPE_API_KEY

    try:
        response = Generation.call(
            api_key=DASHSCOPE_API_KEY,
            model=model,
            prompt=prompt,
            max_tokens=1024,
            temperature=0.5,  # é™ä½éšæœºæ€§ï¼Œè®©å›ç­”æ›´ç¨³å®š
        )

        if response.status_code == 200:
            return response.output.choices[0].message.content
        else:
            return f"âŒ APIè°ƒç”¨å¤±è´¥: {response.code}, {response.message}"

    except Exception as e:
        return f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}"


def get_answer(user_question, history_tuples=None):
    """
    ä¸»å‡½æ•°ï¼šç»“åˆRAGå’ŒLLMï¼Œç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚
    æ”¯æŒï¼š
    - ä»çŸ¥è¯†åº“æ£€ç´¢ï¼ˆRAGï¼‰
    - ä½¿ç”¨å¯¹è¯å†å²ä½œä¸ºä¸Šä¸‹æ–‡ï¼ˆè®°å¿†ï¼‰
    - æ··åˆæ¨¡å¼ï¼šæœ‰çŸ¥è¯†åº“å°±ç”¨çŸ¥è¯†åº“ï¼Œæ²¡æœ‰å°±ç”¨é€šç”¨èƒ½åŠ›
    """
    if history_tuples is None:
        history_tuples = []

    # ============ 1. æ„é€ å¯¹è¯å†å²ä¸Šä¸‹æ–‡ ============
    history_context = ""
    if history_tuples:
        # å°†å†å²å¯¹è¯è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œä½œä¸ºä¸Šä¸‹æ–‡
        history_lines = []
        for user_msg, ai_msg in history_tuples:
            history_lines.append(f"ç”¨æˆ·ï¼š{user_msg}")
            history_lines.append(f"AIï¼š{ai_msg}")
        history_context = "\n\n".join(history_lines)
        history_context = f"ã€è¿‡å¾€å¯¹è¯ã€‘\n{history_context}\n\n"

    # ============ 2. å°è¯•ä»çŸ¥è¯†åº“æ£€ç´¢ ============
    contexts = retrieve_context(user_question, n_results=2)

    # ============ 3. æ„é€ æœ€ç»ˆPrompt ============
    if contexts:
        # æœ‰çŸ¥è¯†åº“ä¿¡æ¯ï¼šä½¿ç”¨RAGæ¨¡å¼ï¼ˆé«˜å‡†ç¡®ï¼‰
        context_str = "\n\n".join(contexts)
        final_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Linuxå‘½ä»¤å­¦ä¹ åŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºç”¨æˆ·å­¦ä¹ Linuxå‘½ä»¤æä¾›å¸®åŠ©ã€‚ä»¥ä¸‹æ˜¯æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼š

ã€å‚è€ƒä¿¡æ¯ã€‘
{context_str}

{history_context}  # â† æ³¨å…¥å†å²ä¸Šä¸‹æ–‡ï¼

è¯·æ ¹æ®ä»¥ä¸Šæä¾›çš„çŸ¥è¯†åº“å†…å®¹ï¼Œä¸ºç”¨æˆ·è§£ç­”é—®é¢˜ã€‚è¦æ±‚ï¼š
1. ä¸¥æ ¼åŸºäºçŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯å›ç­”ï¼Œä¸è¦æ·»åŠ çŸ¥è¯†åº“ä¸­æ²¡æœ‰çš„å†…å®¹
2. å›ç­”è¦æ¸…æ™°ã€ç®€æ´ã€ä¸“ä¸šï¼Œé€‚åˆLinuxå­¦ä¹ è€…ç†è§£
3. å¦‚æœçŸ¥è¯†åº“ä¸­åŒ…å«å‘½ä»¤ç¤ºä¾‹ï¼Œè¯·å®Œæ•´å±•ç¤ºå¹¶è§£é‡Šæ¯ä¸ªå‚æ•°çš„ä½œç”¨
4. å¦‚æœçŸ¥è¯†åº“ä¸­åŒ…å«å¤šä¸ªç›¸å…³ä¿¡æ¯ï¼Œè¯·æ•´åˆæˆä¸€ä¸ªå®Œæ•´çš„å›ç­”
5. åœ¨å›ç­”æœ«å°¾æ ‡æ³¨ä¿¡æ¯æ¥æºï¼ˆå¦‚ï¼šæ ¹æ®Linuxå‘½ä»¤æ‰‹å†Œ/æ ¹æ®çŸ¥è¯†åº“æ–‡æ¡£ï¼‰
6. å¦‚æœç”¨æˆ·è¯¢é—®çš„å‘½ä»¤æœ‰å®‰å…¨é£é™©æˆ–éœ€è¦æ³¨æ„äº‹é¡¹ï¼Œè¯·ç‰¹åˆ«æé†’
7. ä¿æŒæ•™è‚²æ€§å’Œå®ç”¨æ€§ï¼Œå¸®åŠ©ç”¨æˆ·çœŸæ­£ç†è§£å‘½ä»¤çš„ä½¿ç”¨æ–¹æ³•

ã€å½“å‰é—®é¢˜ã€‘
{user_question}

ç°åœ¨è¯·åŸºäºçŸ¥è¯†åº“å†…å®¹ç»™å‡ºä¸“ä¸šè§£ç­”ï¼š"""
    else:
        # æ²¡æœ‰çŸ¥è¯†åº“ä¿¡æ¯ï¼šä½¿ç”¨é€šç”¨é—®ç­”æ¨¡å¼
        final_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Linuxå‘½ä»¤å­¦ä¹ åŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºç”¨æˆ·å­¦ä¹ Linuxå‘½ä»¤æä¾›å¸®åŠ©ã€‚ç»è¿‡æ£€ç´¢ï¼ŒçŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³çš„å…·ä½“ä¿¡æ¯ã€‚
{history_context}  # â† æ³¨å…¥å†å²ä¸Šä¸‹æ–‡ï¼

<system_info>
- å½“å‰æ˜¯é€šç”¨çŸ¥è¯†å›ç­”æ¨¡å¼
- è¯·åŸºäºä½ çš„è®­ç»ƒçŸ¥è¯†å›ç­”Linuxç›¸å…³é—®é¢˜
- é‡ç‚¹å›ç­”æŠ€æœ¯å‡†ç¡®æ€§ï¼Œé¿å…çŒœæµ‹ä¸ç¡®å®šçš„ä¿¡æ¯
- å¦‚æœé—®é¢˜è¶…å‡ºLinuxèŒƒå›´ï¼Œè¯·å‹å¥½å¼•å¯¼å›Linuxä¸»é¢˜
- ä¿æŒä¸“ä¸šã€æ•™è‚²æ€§çš„è¯­æ°”
</system_info>

è¯·æ ¹æ®ä½ çš„é€šç”¨çŸ¥è¯†ä¸ºç”¨æˆ·è§£ç­”é—®é¢˜ã€‚è¦æ±‚ï¼š
1. ä»…å›ç­”ä¸Linuxå‘½ä»¤ã€ç³»ç»Ÿç®¡ç†ã€Shellè„šæœ¬ç›¸å…³çš„æŠ€æœ¯é—®é¢˜
2. ç¡®ä¿æŠ€æœ¯ç»†èŠ‚çš„å‡†ç¡®æ€§ï¼Œç‰¹åˆ«æ˜¯å‘½ä»¤è¯­æ³•ã€å‚æ•°å’Œä½¿ç”¨åœºæ™¯
3. æä¾›å®ç”¨çš„ç¤ºä¾‹ä»£ç ï¼Œå¹¶è§£é‡Šå…³é”®éƒ¨åˆ†
4. æ˜ç¡®æ ‡æ³¨è¿™æ˜¯åŸºäºé€šç”¨çŸ¥è¯†çš„å›ç­”ï¼Œè€Œéæ¥è‡ªç‰¹å®šçŸ¥è¯†åº“
5. å¦‚æœå¯¹æŸäº›ç»†èŠ‚ä¸ç¡®å®šï¼Œè¯·è¯´æ˜å¹¶å»ºè®®ç”¨æˆ·æŸ¥é˜…å®˜æ–¹æ–‡æ¡£
6. å¯¹äºå¤æ‚å‘½ä»¤ï¼Œåˆ†æ­¥éª¤è§£é‡Šä½¿ç”¨æ–¹æ³•
7. æé†’ç”¨æˆ·åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨å‘½ä»¤å‰è¦å……åˆ†æµ‹è¯•

ã€å½“å‰é—®é¢˜ã€‘
{user_question}

ç°åœ¨è¯·åŸºäºä½ çš„é€šç”¨LinuxçŸ¥è¯†ç»™å‡ºä¸“ä¸šè§£ç­”ï¼Œå¹¶åœ¨å¼€å¤´è¯´æ˜"çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œä»¥ä¸‹åŸºäºé€šç”¨LinuxçŸ¥è¯†è§£ç­”ï¼š"ï¼š"""

    # ============ 4. è°ƒç”¨å¤§æ¨¡å‹ ============
    answer = call_qwen_api(final_prompt)
    return answer


# =================== è¿è¡Œæµ‹è¯• ===================
try:
    import gradio as gr

    def chat_interface(user_input, history_messages=None):
        """
        Gradioç•Œé¢çš„å¤„ç†å‡½æ•°ï¼Œä½¿ç”¨openai-style messages æ ¼å¼
        """
        if history_messages is None:
            history_messages = []

        if not user_input.strip():
            return "", history_messages, history_messages
        
        # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°å†å² (ä½¿ç”¨ messages æ ¼å¼)
        history_messages.append({"role": "user", "content": user_input})
        
        # è·å–AIå›ç­” (ç¡®ä¿ get_answer æ”¯æŒ messages æ ¼å¼çš„å†å²)
        ai_response = get_answer(user_input, history_messages)
        
        # å°†AIå›ç­”æ·»åŠ åˆ°å†å²
        history_messages.append({"role": "assistant", "content": ai_response})
        
        # è¿”å›å€¼ï¼šæ¸…ç©ºè¾“å…¥æ¡†ï¼Œæ›´æ–°èŠå¤©å†å²ï¼Œæ›´æ–°çŠ¶æ€
        return "", history_messages, history_messages

    # åˆ›å»ºGradioç•Œé¢
    with gr.Blocks(theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ§ Linuxå‘½ä»¤å°åŠ©æ‰‹")
        gr.Markdown("è¾“å…¥å…³äºLinuxå‘½ä»¤çš„é—®é¢˜ï¼Œæˆ‘ä¼šæ ¹æ®å®˜æ–¹æ–‡æ¡£ä¸ºä½ è§£ç­”ã€‚")
        
        # ä½¿ç”¨Chatbotç»„ä»¶æ˜¾ç¤ºå†å²å¯¹è¯
        # æ³¨æ„ï¼šChatbotæœŸæœ›çš„æ ¼å¼æ˜¯ [[msg1, msg2], ...]ï¼Œå…¶ä¸­msg1æ˜¯ç”¨æˆ·ï¼Œmsg2æ˜¯AI
        chatbot = gr.Chatbot(label="å¯¹è¯å†å²", type="messages", height=650)
        
        with gr.Row():
            with gr.Column(scale=4):
                user_input = gr.Textbox(placeholder="ä¾‹å¦‚ï¼šå¦‚ä½•æŸ¥æ‰¾ä¸€ä¸ªæ–‡ä»¶ï¼Ÿ", label="ä½ çš„é—®é¢˜", scale=4)
            with gr.Column(scale=1):
                submit_btn = gr.Button("å‘é€", variant="primary", scale=1)
        
        # Stateç»„ä»¶ç°åœ¨å­˜å‚¨å…ƒç»„æ ¼å¼çš„å†å²
        history_state = gr.State([]) 
        
        # è®¾ç½®æŒ‰é’®ç‚¹å‡»äº‹ä»¶ï¼Œoutputsé¡ºåºå¿…é¡»æ˜¯ [user_input, chatbot, history_state]
        submit_btn.click(
            fn=chat_interface, 
            inputs=[user_input, history_state], 
            outputs=[user_input, chatbot, history_state] # è¿™é‡Œå®šä¹‰äº†è¾“å‡ºé¡ºåº
        )
        # ä¹Ÿæ”¯æŒæŒ‰å›è½¦é”®æäº¤
        user_input.submit(
            fn=chat_interface, 
            inputs=[user_input, history_state], 
            outputs=[user_input, chatbot, history_state]
        )

    # å¯åŠ¨åº”ç”¨ï¼ˆä»…å½“ç›´æ¥è¿è¡Œæ­¤è„šæœ¬æ—¶ï¼‰
    if __name__ == "__main__":
        print("\nğŸš€ å¯åŠ¨Webç•Œé¢...")
        demo.launch(server_name="127.0.0.1", server_port=7860, share=False)

except ImportError:
    print("\n Gradioæœªå®‰è£…ã€‚å¦‚éœ€Webç•Œé¢ï¼Œè¯·è¿è¡Œ: pip install gradio")